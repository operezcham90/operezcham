<!doctypehtml>
    <html dir="ltr" lang="en">
    <meta charset="utf-8">
    <meta content="width=device-width,initial-scale=1,viewport-fit=cover" name="viewport">
    <title>Oscar Ernesto Perez-Cham, Swarm and Evolutionary Algorithms, Heterogeneous Computing</title>
    <meta
        content="Oscar Ernesto Perez-Cham is currently conducting research on the fields of Swarm and Evolutionary Algorithms, Heterogeneous Computing and Computer Vision."
        name="description">
    <meta content="https://i.imgur.com/dTDz3G9.png" property="og:image">
    <meta content="https://operezcham.xyz" property="og:url">
    <meta content="website" property="og:type">
    <meta content="Oscar Ernesto Perez-Cham" property="og:title">
    <meta content="PhD in Computer Science, Universidad AutÃ³noma de San Luis PotosÃ­ (UASLP)." property="og:description">
    <meta content="summary_large_image" name="twitter:card">
    <link href="https://operezcham.xyz" rel="canonical">
    <link href="/favicon.ico" rel="icon" sizes="any">
    <link href="/icon.svg" rel="icon" type="image/svg+xml">
    <link href="/apple-touch-icon.png" rel="apple-touch-icon">
    <link href="/manifest.webmanifest" rel="manifest">
    <style>
        :root {
            --background-body: #202b38;
            --background: #161f27;
            --background-alt: #1a242f;
            --selection: #1c76c5;
            --text-main: #dbdbdb;
            --text-bright: #fff;
            --text-muted: #a9b1ba;
            --links: #41adff;
            --focus: #0096bfab;
            --border: #526980;
            --code: #ffbe85;
            --animation-duration: 0.1s;
            --button-base: #0c151c;
            --button-hover: #040a0f;
            --scrollbar-thumb: var(--button-hover);
            --scrollbar-thumb-hover: rgb(0, 0, 0);
            --form-placeholder: #a9a9a9;
            --form-text: #fff;
            --variable: #d941e2;
            --highlight: #efdb43
        }

        html {
            scrollbar-color: #040a0f #202b38;
            scrollbar-color: var(--scrollbar-thumb) var(--background-body);
            scrollbar-width: thin
        }

        body {
            font-family: system-ui, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Fira Sans', 'Droid Sans', 'Helvetica Neue', 'Segoe UI Emoji', 'Apple Color Emoji', 'Noto Color Emoji', sans-serif;
            line-height: 1.4;
            max-width: 800px;
            margin: 20px auto;
            padding: 0 10px;
            word-wrap: break-word;
            color: #dbdbdb;
            color: var(--text-main);
            background: #202b38;
            background: var(--background-body);
            text-rendering: optimizeLegibility
        }

        button {
            transition: background-color .1s linear, border-color .1s linear, color .1s linear, box-shadow .1s linear, transform .1s ease;
            transition: background-color var(--animation-duration) linear, border-color var(--animation-duration) linear, color var(--animation-duration) linear, box-shadow var(--animation-duration) linear, transform var(--animation-duration) ease
        }

        input {
            transition: background-color .1s linear, border-color .1s linear, color .1s linear, box-shadow .1s linear, transform .1s ease;
            transition: background-color var(--animation-duration) linear, border-color var(--animation-duration) linear, color var(--animation-duration) linear, box-shadow var(--animation-duration) linear, transform var(--animation-duration) ease
        }

        textarea {
            transition: background-color .1s linear, border-color .1s linear, color .1s linear, box-shadow .1s linear, transform .1s ease;
            transition: background-color var(--animation-duration) linear, border-color var(--animation-duration) linear, color var(--animation-duration) linear, box-shadow var(--animation-duration) linear, transform var(--animation-duration) ease
        }

        .h1-abbrev,
        h1 {
            font-size: 2.2em;
            margin-top: 0
        }

        .h1-abbrev,
        h1,
        h2,
        h3,
        h4,
        h5,
        h6 {
            margin-bottom: 12px;
            margin-top: 24px
        }

        .h1-abbrev,
        h1 {
            color: #fff;
            color: var(--text-bright)
        }

        h2 {
            color: #fff;
            color: var(--text-bright)
        }

        h3 {
            color: #fff;
            color: var(--text-bright)
        }

        h4 {
            color: #fff;
            color: var(--text-bright)
        }

        h5 {
            color: #fff;
            color: var(--text-bright)
        }

        h6 {
            color: #fff;
            color: var(--text-bright)
        }

        strong {
            color: #fff;
            color: var(--text-bright)
        }

        .h1-abbrev,
        b,
        h1,
        h2,
        h3,
        h4,
        h5,
        h6,
        strong,
        th {
            font-weight: 600
        }

        q::before {
            content: none
        }

        q::after {
            content: none
        }

        blockquote {
            border-left: 4px solid #0096bfab;
            border-left: 4px solid var(--focus);
            margin: 1.5em 0;
            padding: .5em 1em;
            font-style: italic
        }

        q {
            border-left: 4px solid #0096bfab;
            border-left: 4px solid var(--focus);
            margin: 1.5em 0;
            padding: .5em 1em;
            font-style: italic
        }

        blockquote>footer {
            font-style: normal;
            border: 0
        }

        blockquote cite {
            font-style: normal
        }

        address {
            font-style: normal
        }

        mark {
            background-color: #efdb43;
            background-color: var(--highlight);
            border-radius: 2px;
            padding: 0 2px 0 2px;
            color: #000
        }

        a>code,
        a>strong {
            color: inherit
        }

        button,
        input[type=button],
        input[type=checkbox],
        input[type=radio],
        input[type=range],
        input[type=reset],
        input[type=submit] {
            cursor: pointer
        }

        input {
            display: block
        }

        [type=checkbox],
        [type=radio] {
            display: initial
        }

        input {
            color: #fff;
            color: var(--form-text);
            background-color: #161f27;
            background-color: var(--background);
            font-family: inherit;
            font-size: inherit;
            margin-right: 6px;
            margin-bottom: 6px;
            padding: 10px;
            border: none;
            border-radius: 6px;
            outline: 0
        }

        button {
            color: #fff;
            color: var(--form-text);
            background-color: #161f27;
            background-color: var(--background);
            font-family: inherit;
            font-size: inherit;
            margin-right: 6px;
            margin-bottom: 6px;
            padding: 10px;
            border: none;
            border-radius: 6px;
            outline: 0
        }

        textarea {
            color: #fff;
            color: var(--form-text);
            background-color: #161f27;
            background-color: var(--background);
            font-family: inherit;
            font-size: inherit;
            margin-right: 6px;
            margin-bottom: 6px;
            padding: 10px;
            border: none;
            border-radius: 6px;
            outline: 0
        }

        button {
            background-color: #0c151c;
            background-color: var(--button-base);
            padding-right: 30px;
            padding-left: 30px
        }

        input[type=submit] {
            background-color: #0c151c;
            background-color: var(--button-base);
            padding-right: 30px;
            padding-left: 30px
        }

        input[type=reset] {
            background-color: #0c151c;
            background-color: var(--button-base);
            padding-right: 30px;
            padding-left: 30px
        }

        input[type=button] {
            background-color: #0c151c;
            background-color: var(--button-base);
            padding-right: 30px;
            padding-left: 30px
        }

        button:hover {
            background: #040a0f;
            background: var(--button-hover)
        }

        input[type=submit]:hover {
            background: #040a0f;
            background: var(--button-hover)
        }

        input[type=reset]:hover {
            background: #040a0f;
            background: var(--button-hover)
        }

        input[type=button]:hover {
            background: #040a0f;
            background: var(--button-hover)
        }

        input[type=color] {
            min-height: 2rem;
            padding: 8px;
            cursor: pointer
        }

        input[type=checkbox],
        input[type=radio] {
            height: 1em;
            width: 1em
        }

        input[type=radio] {
            border-radius: 100%
        }

        input {
            vertical-align: top
        }

        label {
            vertical-align: middle;
            margin-bottom: 4px;
            display: inline-block
        }

        button,
        input:not([type=checkbox]):not([type=radio]),
        input[type=range],
        textarea {
            appearance: none
        }

        textarea {
            display: block;
            margin-right: 0;
            box-sizing: border-box;
            resize: vertical
        }

        textarea:not([cols]) {
            width: 100%
        }

        textarea:not([rows]) {
            min-height: 40px;
            height: 140px
        }

        input:focus {
            box-shadow: 0 0 0 2px #0096bfab;
            box-shadow: 0 0 0 2px var(--focus)
        }

        button:focus {
            box-shadow: 0 0 0 2px #0096bfab;
            box-shadow: 0 0 0 2px var(--focus)
        }

        textarea:focus {
            box-shadow: 0 0 0 2px #0096bfab;
            box-shadow: 0 0 0 2px var(--focus)
        }

        button:active,
        input[type=button]:active,
        input[type=checkbox]:active,
        input[type=radio]:active,
        input[type=range]:active,
        input[type=reset]:active,
        input[type=submit]:active {
            transform: translateY(2px)
        }

        button:disabled,
        input:disabled,
        textarea:disabled {
            cursor: not-allowed;
            opacity: .5
        }

        ::-moz-placeholder {
            color: #a9a9a9;
            color: var(--form-placeholder)
        }

        :-ms-input-placeholder {
            color: #a9a9a9;
            color: var(--form-placeholder)
        }

        ::-ms-input-placeholder {
            color: #a9a9a9;
            color: var(--form-placeholder)
        }

        ::placeholder {
            color: #a9a9a9;
            color: var(--form-placeholder)
        }

        fieldset {
            border: 1px #0096bfab solid;
            border: 1px var(--focus) solid;
            border-radius: 6px;
            margin: 0;
            margin-bottom: 12px;
            padding: 10px
        }

        legend {
            font-size: .9em;
            font-weight: 600
        }

        input[type=range] {
            margin: 10px 0;
            padding: 10px 0;
            background: 0 0
        }

        input[type=range]:focus {
            outline: 0
        }

        input[type=range]::-webkit-slider-runnable-track {
            width: 100%;
            height: 9.5px;
            -webkit-transition: .2s;
            transition: .2s;
            background: #161f27;
            background: var(--background);
            border-radius: 3px
        }

        input[type=range]::-webkit-slider-thumb {
            box-shadow: 0 1px 1px #000, 0 0 1px #0d0d0d;
            height: 20px;
            width: 20px;
            border-radius: 50%;
            background: #526980;
            background: var(--border);
            -webkit-appearance: none;
            margin-top: -7px
        }

        input[type=range]:focus::-webkit-slider-runnable-track {
            background: #161f27;
            background: var(--background)
        }

        input[type=range]::-moz-range-track {
            width: 100%;
            height: 9.5px;
            -moz-transition: .2s;
            transition: .2s;
            background: #161f27;
            background: var(--background);
            border-radius: 3px
        }

        input[type=range]::-moz-range-thumb {
            box-shadow: 1px 1px 1px #000, 0 0 1px #0d0d0d;
            height: 20px;
            width: 20px;
            border-radius: 50%;
            background: #526980;
            background: var(--border)
        }

        input[type=range]::-ms-track {
            width: 100%;
            height: 9.5px;
            background: 0 0;
            border-color: transparent;
            border-width: 16px 0;
            color: transparent
        }

        input[type=range]::-ms-fill-lower {
            background: #161f27;
            background: var(--background);
            border: .2px solid #010101;
            border-radius: 3px;
            box-shadow: 1px 1px 1px #000, 0 0 1px #0d0d0d
        }

        input[type=range]::-ms-fill-upper {
            background: #161f27;
            background: var(--background);
            border: .2px solid #010101;
            border-radius: 3px;
            box-shadow: 1px 1px 1px #000, 0 0 1px #0d0d0d
        }

        input[type=range]::-ms-thumb {
            box-shadow: 1px 1px 1px #000, 0 0 1px #0d0d0d;
            border: 1px solid #000;
            height: 20px;
            width: 20px;
            border-radius: 50%;
            background: #526980;
            background: var(--border)
        }

        input[type=range]:focus::-ms-fill-lower {
            background: #161f27;
            background: var(--background)
        }

        input[type=range]:focus::-ms-fill-upper {
            background: #161f27;
            background: var(--background)
        }

        a {
            text-decoration: none;
            color: #41adff;
            color: var(--links)
        }

        a:hover {
            text-decoration: underline
        }

        code {
            background: #161f27;
            background: var(--background);
            color: #ffbe85;
            color: var(--code);
            padding: 2.5px 5px;
            border-radius: 6px;
            font-size: 1em
        }

        samp {
            background: #161f27;
            background: var(--background);
            color: #ffbe85;
            color: var(--code);
            padding: 2.5px 5px;
            border-radius: 6px;
            font-size: 1em
        }

        time {
            background: #161f27;
            background: var(--background);
            color: #ffbe85;
            color: var(--code);
            padding: 2.5px 5px;
            border-radius: 6px;
            font-size: 1em
        }

        pre>code {
            padding: 10px;
            display: block;
            overflow-x: auto
        }

        var {
            color: #d941e2;
            color: var(--variable);
            font-style: normal;
            font-family: monospace
        }

        kbd {
            background: #161f27;
            background: var(--background);
            border: 1px solid #526980;
            border: 1px solid var(--border);
            border-radius: 2px;
            color: #dbdbdb;
            color: var(--text-main);
            padding: 2px 4px 2px 4px
        }

        img,
        video {
            max-width: 100%;
            height: auto
        }

        hr {
            border: none;
            border-top: 1px solid #526980;
            border-top: 1px solid var(--border)
        }

        table {
            border-collapse: collapse;
            margin-bottom: 10px;
            width: 100%;
            table-layout: fixed
        }

        table caption {
            text-align: left
        }

        td,
        th {
            padding: 6px;
            text-align: left;
            vertical-align: top;
            word-wrap: break-word
        }

        thead {
            border-bottom: 1px solid #526980;
            border-bottom: 1px solid var(--border)
        }

        tfoot {
            border-top: 1px solid #526980;
            border-top: 1px solid var(--border)
        }

        tbody tr:nth-child(even) {
            background-color: #161f27;
            background-color: var(--background)
        }

        tbody tr:nth-child(even) button {
            background-color: #1a242f;
            background-color: var(--background-alt)
        }

        tbody tr:nth-child(even) button:hover {
            background-color: #202b38;
            background-color: var(--background-body)
        }

        ::-webkit-scrollbar {
            height: 10px;
            width: 10px
        }

        ::-webkit-scrollbar-track {
            background: #161f27;
            background: var(--background);
            border-radius: 6px
        }

        ::-webkit-scrollbar-thumb {
            background: #040a0f;
            background: var(--scrollbar-thumb);
            border-radius: 6px
        }

        ::-webkit-scrollbar-thumb:hover {
            background: #000;
            background: var(--scrollbar-thumb-hover)
        }

        ::-moz-selection {
            background-color: #1c76c5;
            background-color: var(--selection);
            color: #fff;
            color: var(--text-bright)
        }

        ::selection {
            background-color: #1c76c5;
            background-color: var(--selection);
            color: #fff;
            color: var(--text-bright)
        }

        details {
            display: flex;
            flex-direction: column;
            align-items: flex-start;
            background-color: #1a242f;
            background-color: var(--background-alt);
            padding: 10px 10px 0;
            margin: 1em 0;
            border-radius: 6px;
            overflow: hidden
        }

        details[open] {
            padding: 10px
        }

        details>:last-child {
            margin-bottom: 0
        }

        details[open] summary {
            margin-bottom: 10px
        }

        summary {
            display: list-item;
            background-color: #161f27;
            background-color: var(--background);
            padding: 10px;
            margin: -10px -10px 0;
            cursor: pointer;
            outline: 0
        }

        summary:focus,
        summary:hover {
            text-decoration: underline
        }

        details>:not(summary) {
            margin-top: 0
        }

        summary::-webkit-details-marker {
            color: #dbdbdb;
            color: var(--text-main)
        }

        dialog {
            background-color: #1a242f;
            background-color: var(--background-alt);
            color: #dbdbdb;
            color: var(--text-main);
            border: none;
            border-radius: 6px;
            border-color: #526980;
            border-color: var(--border);
            padding: 10px 30px
        }

        dialog>header:first-child {
            background-color: #161f27;
            background-color: var(--background);
            border-radius: 6px 6px 0 0;
            margin: -10px -30px 10px;
            padding: 10px;
            text-align: center
        }

        dialog::-webkit-backdrop {
            background: #0000009c;
            -webkit-backdrop-filter: blur(4px);
            backdrop-filter: blur(4px)
        }

        dialog::backdrop {
            background: #0000009c;
            -webkit-backdrop-filter: blur(4px);
            backdrop-filter: blur(4px)
        }

        footer {
            border-top: 1px solid #526980;
            border-top: 1px solid var(--border);
            padding-top: 10px;
            color: #a9b1ba;
            color: var(--text-muted)
        }

        body>footer {
            margin-top: 40px
        }

        @media print {

            body,
            button,
            code,
            details,
            input,
            pre,
            summary,
            textarea {
                background-color: #fff
            }

            button,
            input,
            textarea {
                border: 1px solid #000
            }

            .h1-abbrev,
            body,
            button,
            code,
            footer,
            h1,
            h2,
            h3,
            h4,
            h5,
            h6,
            input,
            pre,
            strong,
            summary,
            textarea {
                color: #000
            }

            summary::marker {
                color: #000
            }

            summary::-webkit-details-marker {
                color: #000
            }

            tbody tr:nth-child(even) {
                background-color: #f2f2f2
            }

            a {
                color: #00f;
                text-decoration: underline
            }
        }

        .emoji {
            height: 1em;
            width: 1em;
            margin: 0 .05em 0 .1em;
            vertical-align: -.1em
        }

        .h1-abbrev,
        .short {
            display: none
        }

        .pic {
            border-radius: 50%;
            float: left;
            margin-right: 1em;
            margin-bottom: 2em
        }

        @media only screen and (max-width:750px) {

            .long,
            h1 {
                display: none
            }

            .h1-abbrev {
                display: block
            }

            .short {
                display: inline
            }

            .pic {
                float: none;
                margin-bottom: -2em
            }
        }
    </style>
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-VSCD9R9T0J"></script>
    <script>function gtag() { dataLayer.push(arguments) } window.dataLayer = window.dataLayer || [], gtag("js", new Date), gtag("config", "G-VSCD9R9T0J")</script>

    <body itemscope itemtype="https://schema.org/Person">
        <header><img alt="ðŸ‘¤" class="pic"
                src="https://i1.rgstatic.net/ii/profile.image/11431281127366124-1679005522173_Q128/Oscar-Perez-Cham.jpg"
                height="100" itemprop="image" width="100">
            <h1 itemprop="name">OscarÂ Ernesto Perezâ€‘Cham</h1>
            <div class="h1-abbrev">Perezâ€‘Cham,Â O.Â E.</div>
            <hr><img alt="ðŸ“Œ" class="emoji" src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f4cc.svg">
            <a
                href="https://www.researchgate.net/publication/355093993_Development_of_Heterogeneous_Systems_Based_on_the_Honeybee_Search_Algorithm_for_Video_Tracking"><span
                    itemprop="honorificSuffix">PhD in ComputerÂ Science</span></a>, Professor at <a
                href="https://web.facebook.com/SOYUMAR.OAXACA" itemprop="affiliation" class="long"
                lang="es">UniversidadÂ del Mar</a><a href="https://web.facebook.com/SOYUMAR.OAXACA"
                class="short">UMAR</a>
        </header>
        <nav><img alt="ðŸ”—" class="emoji" src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f517.svg"> <a
                href="https://orcid.org/0000-0002-0110-5475" itemprop="identifier">ORCiD</a><span class="long">, <a
                    href="https://www.researchgate.net/profile/Oscar-Perez-Cham">ResearchGate</a>, <a
                    href="https://scholar.google.com/citations?user=85PU7UoAAAAJ">GoogleÂ Scholar</a>, <a
                    href="https://github.com/operezcham90">GitHub</a>, <a
                    href="https://www.scopus.com/authid/detail.uri?authorId=57207875425">Scopus</a>, <a
                    href="https://www.webofscience.com/wos/author/record/ABA-3528-2021">Web of Science</a>, <a
                    href="https://www.linkedin.com/in/operezcham">LinkedIn</a></span></nav>
        <section>
            <h2>JournalÂ articles</h2>
            <hr><img alt="ðŸ“„" class="emoji" src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f4c4.svg">
            <a href="https://orcid.org/0000-0002-0179-3933" itemprop="colleague">Soubervielleâ€‘Montalvo,Â C.</a>, <a
                href="https://orcid.org/0000-0002-0110-5475" itemprop="identifier">Perezâ€‘Cham,Â O.Â E.</a>, <a
                href="https://orcid.org/0000-0002-2435-3340" itemprop="colleague">Puente,Â C.</a>, <a
                href="https://orcid.org/0000-0002-5682-0070" itemprop="colleague">Gonzalezâ€‘Galvan,Â E.Â J.</a>, <a
                href="https://orcid.org/0000-0001-5773-9517" itemprop="colleague">Olague,Â G.</a>, <a
                href="https://orcid.org/0000-0003-3422-7193" itemprop="colleague">Aguirreâ€‘Salado,Â C.Â A.</a>, <a
                href="https://orcid.org/0000-0002-7566-0412" itemprop="colleague">Cuevasâ€‘Tello,Â J.Â C.</a>, & <a
                href="https://orcid.org/0000-0002-6042-6893" itemprop="colleague">Ontanonâ€‘Garcia,Â L.Â J.</a> (2022). <a
                href="https://www.mdpi.com/1424-8220/22/3/1280">Design of a Lowâ€‘Power Embedded System Based on a
                SoCâ€‘FPGA and the HoneybeeÂ SearchÂ Algorithm for Realâ€‘Time VideoÂ Tracking</a>. InÂ <a
                href="https://www.mdpi.com/journal/sensors">Sensors</a> (Vol.Â <a
                href="https://www.mdpi.com/1424-8220/22">22</a>, IssueÂ <a
                href="https://www.mdpi.com/1424-8220/22/3">3</a>, p.Â <a
                href="https://www.mdpi.com/1424-8220/22/3/1280">1280</a>). <a href="https://www.mdpi.com/">MDPIÂ AG</a>.
            <a href="https://doi.org/10.3390/s22031280">https://doi.org/10.3390/s22031280</a>
            <details>
                <summary>More</summary>
                <p><a href="https://www.mdpi.com/1424-8220/22/3/1280/htm">Open access</a>. <a
                        href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85124328277&origin=inward">One
                        citation</a>.
                <p>heterogeneous computing; meta-heuristic; video tracking; system-on-chip; field-programmable gate
                    array; evolutionary computing; swarm intelligence; embedded system design; graphics processing unit;
                    computer vision
                <p>Video tracking involves detecting previously designated objects of interest within a sequence of
                    image frames. It can be applied in robotics, unmanned vehicles, and automation, among other fields
                    of interest. Video tracking is still regarded as an open problem due to a number of obstacles that
                    still need to be overcome, including the need for high precision and realâ€‘time results, as well as
                    portability and lowâ€‘power demands. This work presents the design, implementation and assessment of a
                    lowâ€‘power embedded system based on an SoCâ€‘FPGA platform and the honeybee search algorithm (HSA) for
                    realâ€‘time video tracking. HSA is a metaâ€‘heuristic that combines evolutionary computing and swarm
                    intelligence techniques. Our findings demonstrated that the combination of SoCâ€‘FPGA and HSA reduced
                    the consumption of computational resources, allowing realâ€‘time multiprocessing without a reduction
                    in precision, and with the advantage of lower power consumption, which enabled portability. A
                    starker difference was observed when measuring the power consumption. The proposed SoCâ€‘FPGA system
                    consumed about 5 Watts, whereas the CPUâ€‘GPU system required more than 200 Watts. A general
                    recommendation obtained from this research is to use SoCâ€‘FPGA over CPUâ€‘GPU to work with
                    metaâ€‘heuristics in computer vision applications when an embedded solution is required.</p>
                <code>@article{Soubervielle_Montalvo_2022, doi = {10.3390/s22031280}, year = 2022, month = {feb}, publisher = {{MDPI} {AG}}, volume = {22}, number = {3}, pages = {1280}, author = {Carlos Soubervielle-Montalvo and Oscar E. Perez-Cham and Cesar Puente and Emilio J. Gonzalez-Galvan and Gustavo Olague and Carlos A. Aguirre-Salado and Juan C. Cuevas-Tello and Luis J. Ontanon-Garcia}, title = {Design of a Low-Power Embedded System Based on a {SoC}-{FPGA} and the Honeybee Search Algorithm for Real-Time Video Tracking}, journal = {Sensors} }</code>
            </details><img alt="ðŸ“„" class="emoji"
                src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f4c4.svg"> <a
                href="https://orcid.org/0000-0002-0110-5475" itemprop="identifier">Perezâ€‘Cham,Â O.Â E.</a>, <a
                href="https://orcid.org/0000-0002-2435-3340" itemprop="colleague">Puente,Â C.</a>, <a
                href="https://orcid.org/0000-0002-0179-3933" itemprop="colleague">Soubervielleâ€‘Montalvo,Â C.</a>, <a
                href="https://orcid.org/0000-0001-5773-9517" itemprop="colleague">Olague,Â G.</a>, <a
                href="https://orcid.org/0000-0001-7821-5819" itemprop="colleague">Castilloâ€‘Barrera,Â F.â€‘E.</a>, <a
                href="https://orcid.org/0000-0002-9633-3453" itemprop="colleague">Nunezâ€‘Varela,Â J.</a>, & <a
                href="https://orcid.org/0000-0003-2117-4803" itemprop="colleague">Limonâ€‘Romero,Â J.</a> (2021). <a
                href="https://www.sciencedirect.com/science/article/abs/pii/S2210650220304703">Automata design for
                honeybeeÂ searchÂ algorithm and its applications to 3DÂ scene reconstruction and videoÂ tracking</a>. InÂ <a
                href="https://www.sciencedirect.com/journal/swarm-and-evolutionary-computation">Swarm and
                EvolutionaryÂ Computation</a> (Vol.Â <a
                href="https://www.sciencedirect.com/journal/swarm-and-evolutionary-computation/vol/61/suppl/C">61</a>,
            p.Â <a href="https://www.sciencedirect.com/science/article/abs/pii/S2210650220304703">100817</a>). <a
                href="https://www.elsevier.com/books-and-journals">ElsevierÂ BV</a>. <a
                href="https://doi.org/10.1016/j.swevo.2020.100817">https://doi.org/10.1016/j.swevo.2020.100817</a>
            <details>
                <summary>More</summary>
                <p><a
                        href="https://www.researchgate.net/publication/347430726_Automata_Design_for_Honeybee_Search_Algorithm_and_Its_Applications_to_3D_Scene_Reconstruction_and_Video_Tracking">Request
                        access</a>. <a
                        href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85098737592&origin=inward">Four
                        citations</a>.
                <p>swarm intelligence; evolutionary algorithms; meta-heuristic; video tracking; three-dimensional scene
                    reconstruction
                <p>Honeybees, as social insects, follow a modular strategy applied to dynamic environments to provide
                    reasonable opportunities for partial solutions to evolve in the form of interacting coadapted
                    subcomponents. The honeybee search algorithm combines concepts from the areas of evolutionary
                    algorithms and swarm intelligence to solve optimization problems. This algorithm is mainly based on
                    the foraging behavior of honeybees and the search power of evolution strategies, a type of
                    evolutionary algorithm used for real-valued problems. This paper shows the integration between an
                    automaton and the honeybee search algorithm to formalize the algorithm mathematically. The
                    combination mentioned above is tested here with the innovative applications of three-dimensional
                    scene reconstruction and video tracking. The experimental results for both applications show
                    evidence that the honeybee search algorithm can be used to improve time costs in challenging
                    computer vision tasks through controlled experiments and objective comparisons. Also, the validation
                    of results demonstrates that the measured accuracy ranks top-tier among other algorithms in the
                    ALOV++ benchmark.</p>
                <code>@article{Perez_Cham_2021, doi = {10.1016/j.swevo.2020.100817}, year = 2021, month = {mar}, publisher = {Elsevier {BV}}, volume = {61}, pages = {100817}, author = {Oscar E. Perez-Cham and Cesar Puente and Carlos Soubervielle-Montalvo and Gustavo Olague and Francisco-Edgar Castillo-Barrera and Jose Nunez-Varela and Jorge Limon-Romero}, title = {Automata design for honeybee search algorithm and its applications to 3D scene reconstruction and video tracking}, journal = {Swarm and Evolutionary Computation} }</code>
            </details><img alt="ðŸ“„" class="emoji"
                src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f4c4.svg"> <a
                href="https://orcid.org/0000-0003-4813-8992" itemprop="colleague">NuÃ±ezâ€‘Varela,Â A.Â S.</a>, <a
                href="https://orcid.org/0000-0003-3331-2230" itemprop="colleague">PÃ©rezâ€‘Gonzalez,Â H.Â G.</a>, <a
                href="https://orcid.org/0000-0002-3133-9045" itemprop="colleague">MartÃ­nezâ€‘Perez,Â F.Â E.</a>, <a
                href="https://orcid.org/0000-0002-0179-3933" itemprop="colleague">Soubervielleâ€‘Montalvo,Â C.</a>, & <a
                href="https://orcid.org/0000-0002-0110-5475" itemprop="identifier">Perezâ€‘Cham,Â O.Â E.</a> (2020). <a
                href="https://www.sciencedirect.com/science/article/abs/pii/S0167642320300903">Dynamic creation of
                source code models for the extraction of code metrics data through grammar querying</a>. InÂ <a
                href="https://www.sciencedirect.com/journal/science-of-computer-programming">Science of
                ComputerÂ Programming</a> (Vol.Â <a
                href="https://www.sciencedirect.com/journal/science-of-computer-programming/vol/196/suppl/C">196</a>,
            p.Â <a href="https://www.sciencedirect.com/science/article/abs/pii/S0167642320300903">102480</a>). <a
                href="https://www.elsevier.com/books-and-journals">ElsevierÂ BV</a>. <a
                href="https://doi.org/10.1016/j.scico.2020.102480">https://doi.org/10.1016/j.scico.2020.102480</a>
            <details>
                <summary>More</summary>
                <p><a
                        href="https://www.researchgate.net/publication/341484862_Dynamic_creation_of_source_code_models_for_the_extraction_of_code_metrics_data_through_grammar_querying">Request
                        access</a>.
                <p>source code metrics; metrics extraction; software metrics tool
                <p>Source code metrics extraction is a complex task that has to be done automatically given the current
                    size of software. They are extracted using software metric tools and more generic extraction
                    mechanisms. These mechanisms usually work by querying a source code representation model. These
                    models are static, and the information that can be obtained from them is limited. In this work an
                    extraction methodology is presented in which the model is created every time certain information is
                    needed. This is accomplished by querying the language context-free grammar, and from the information
                    obtained by the query, a dynamic model is created. Current extraction mechanisms work by querying a
                    model, while the proposed methodology queries the grammar directly, thus the model is created
                    afterwards from the query result, and contains all the needed information. A metrics tool is created
                    based on the proposed methodology, and in order to prove the correct functioning of extracting the
                    desired information from the source code, not as already predefined as in current tools, several
                    metrics are extracted as defined by four existing metrics tools. Querying the language grammar
                    allows access to all available data in the source code, regardless of the programming language and
                    paradigm.</p>
                <code>@article{Nu_ez_Varela_2020, doi = {10.1016/j.scico.2020.102480}, year = 2020, month = {sep}, publisher = {Elsevier {BV}}, volume = {196}, pages = {102480}, author = {Alberto S. Nu{\~{n}}ez-Varela and H{\'{e}}ctor G. P{\'{e}}rez-Gonzalez and Francisco E. Mart{\'{\i}}nez-Perez and Carlos Soubervielle-Montalvo and Oscar E. Perez-Cham}, title = {Dynamic creation of source code models for the extraction of code metrics data through grammar querying}, journal = {Science of Computer Programming} }</code>
            </details><img alt="ðŸ“„" class="emoji"
                src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f4c4.svg"> <a
                href="https://orcid.org/0000-0002-0110-5475" itemprop="identifier">Perezâ€‘Cham,Â O.Â E.</a>, <a
                href="https://orcid.org/0000-0002-2435-3340" itemprop="colleague">Puente,Â C.</a>, <a
                href="https://orcid.org/0000-0002-0179-3933" itemprop="colleague">Soubervielleâ€‘Montalvo,Â C.</a>, <a
                href="https://orcid.org/0000-0001-5773-9517" itemprop="colleague">Olague,Â G.</a>, <a
                href="https://orcid.org/0000-0003-3422-7193" itemprop="colleague">Aguirreâ€‘Salado,Â C.Â A.</a>, & <a
                href="https://orcid.org/0000-0003-4813-8992" itemprop="colleague">NuÃ±ezâ€‘Varela,Â A.Â S.</a> (2020). <a
                href="https://www.mdpi.com/2076-3417/10/6/2122">Parallelization of the HoneybeeÂ SearchÂ Algorithm for
                ObjectÂ Tracking</a>. InÂ <a href="https://www.mdpi.com/journal/applsci">AppliedÂ Sciences</a> (Vol.Â <a
                href="https://www.mdpi.com/2076-3417/10">10</a>, IssueÂ <a
                href="https://www.mdpi.com/2076-3417/10/6">6</a>, p.Â <a
                href="https://www.mdpi.com/2076-3417/10/6/2122">2122</a>). <a href="https://www.mdpi.com/">MDPIÂ AG</a>.
            <a href="https://doi.org/10.3390/app10062122">https://doi.org/10.3390/app10062122</a>
            <details>
                <summary>More</summary>
                <p><a href="https://www.mdpi.com/2076-3417/10/6/2122/htm">Open access</a>. <a
                        href="https://www.scopus.com/inward/citedby.uri?partnerID=HzOxMe3b&scp=85082723977&origin=inward">Eleven
                        citations</a>.
                <p>object tracking; honeybee search algorithm; swarm intelligence; parallel computing; graphics
                    processing unit
                <p>Object tracking refers to the relocation of specific objects in consecutive frames of a video
                    sequence. Presently, this visual task is still considered an open research issue, and the computer
                    science community attempted solutions from the standpoint of methodologies, algorithms, criteria,
                    benchmarks, and so on. This article introduces a GPU-parallelized swarm algorithm, called the
                    Honeybee Search Algorithm (HSA), which is a hybrid algorithm combining swarm intelligence and
                    evolutionary algorithm principles, and was previously designed for three-dimensional reconstruction.
                    This heuristic inspired by the search for food of honeybees, and here adapted to the problem of
                    object tracking using GPU parallel computing, is extended from the original proposal of HSA towards
                    video processing. In this work, the normalized cross-correlation (NCC) criteria is used as the
                    fitness function. Experiments using 314 video sequences of the ALOV benchmark provides evidence
                    about the quality regarding tracking accuracy and processing time. Also, according to these
                    experiments, the proposed methodology is robust to high levels of Gaussian noise added to the image
                    frames, and this confirms that the accuracy of the original NCC is preserved with the advantage of
                    acceleration, offering the possibility of accelerating latest trackers using this methodology.</p>
                <code>@article{Perez_Cham_2020, doi = {10.3390/app10062122}, year = 2020, month = {mar}, publisher = {{MDPI} {AG}}, volume = {10}, number = {6}, pages = {2122}, author = {Oscar E. Perez-Cham and Cesar Puente and Carlos Soubervielle-Montalvo and Gustavo Olague and Carlos A. Aguirre-Salado and Alberto S. Nu{\~{n}}ez-Varela}, title = {Parallelization of the Honeybee Search Algorithm for Object Tracking}, journal = {Applied Sciences} }</code>
            </details>
        </section>
        <section>
            <h2>ConferenceÂ articles</h2>
            <hr><img alt="ðŸ“„" class="emoji" src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f4c4.svg">
            <a href="https://orcid.org/0000-0002-0110-5475" itemprop="identifier">Perezâ€‘Cham,Â O.Â E.</a>, <a
                href="https://orcid.org/0000-0002-0179-3933" itemprop="colleague">Soubervielleâ€‘Montalvo,Â C.</a>, <a
                href="https://orcid.org/0000-0003-4813-8992" itemprop="colleague">NuÃ±ezâ€‘Varela,Â A.Â S.</a>, <a
                href="https://orcid.org/0000-0002-2435-3340" itemprop="colleague">Puente,Â C.</a>, & <a
                href="https://orcid.org/0000-0002-6042-6893" itemprop="colleague">Ontanonâ€‘Garcia,Â L.Â J.</a> (2018). <a
                href="https://ieeexplore.ieee.org/document/8645854">Source Code Metrics to Predict the Properties of
                FPGA/VHDLâ€‘Based Synthesized Products</a>. InÂ <a
                href="https://ieeexplore.ieee.org/xpl/conhome/8637588/proceeding">2018 6th International Conference in
                Software Engineering Research and InnovationÂ (CONISOFT)</a>. <a href="https://www.ieee.org/">IEEE</a>.
            <a href="https://doi.org/10.1109/conisoft.2018.8645854">https://doi.org/10.1109/conisoft.2018.8645854</a>
            <details>
                <summary>More</summary>
                <p><a
                        href="https://www.researchgate.net/publication/331266275_Source_Code_Metrics_to_Predict_the_Properties_of_FPGAVHDL-Based_Synthesized_Products">Request
                        access</a>.
                <p>field programmable gate arrays; hardware description languages; object-oriented programming; software
                    metrics; source code (software); very high speed integrated circuits
                <p>Current research on source code metrics is heavily focused on measuring quality attributes for object
                    oriented source code, for common languages such as C++, Java and C#. However, source code metrics
                    are good predictors and evaluators of software systems characteristics, thereby researchers have
                    found other uses and applications for other computing related areas. In this research, source code
                    metrics for Very High Speed Integrated Circuit Hardware Description Language (VHDL) are proposed and
                    used to predict the synthesized product properties for Field Programmable Gate Array (FPGA) based
                    digital systems. Code written in VHDL is used to generate a configuration file for a specific FPGA
                    in a process named design synthesis. Physical properties of the FPGA/VHDL based synthesized product
                    are measured for performance evaluation in a testing process, but it can be a time consuming
                    process. In this paper we aim to correlate source code metrics with the FPGA/VHDL based synthesized
                    product properties, in order to determine if source code metrics can be used as predictors of
                    certain synthesized product properties. A case of study correlating three source code metrics with
                    three synthesized product properties is presented. The results of the study provide evidence that
                    source code metrics can be used as predictors of FPGA/VHDL based synthesized product properties.</p>
                <code>@inproceedings{Perez_Cham_2018, doi = {10.1109/conisoft.2018.8645854}, year = 2018, month = {oct}, publisher = {{IEEE}}, author = {Oscar E. Perez-Cham and Carlos Soubervielle-Montalvo and Alberto S. Nunez-Varela and Cesar Puente and Luis J. Ontanon-Garcia}, title = {Source Code Metrics to Predict the Properties of {FPGA}/{VHDL}-Based Synthesized Products}, booktitle = {2018 6th International Conference in Software Engineering Research and Innovation ({CONISOFT})} }</code>
            </details>
            <hr><img alt="ðŸ“„" class="emoji" src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f4c4.svg">
            Fortuna-Cervantes, J. M., Soubervielle-Montalvo, C., Perez-Cham, O. E., PeÃ±a-Gallardo, R., & Puente, C.
            (2023). Experimental Study of the Performance of Convolutional Neural Networks Applied in Art Media
            Classification. In Lecture Notes in Computer Science (pp. 169â€“178). Springer Nature Switzerland.
            https://doi.org/10.1007/978-3-031-33783-3_16
        </section>
        <section>
            <h2>Theses</h2>
            <hr><img alt="ðŸ“˜" class="emoji" src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f4d8.svg"><a
                href="https://orcid.org/0000-0002-0110-5475" itemprop="identifier"> Perezâ€‘Cham,Â O.Â E.</a> (2021). <a
                href="https://www.researchgate.net/publication/355093993_Development_of_Heterogeneous_Systems_Based_on_the_Honeybee_Search_Algorithm_for_Video_Tracking">Development
                of Heterogeneous Systems Based on the Honeybee Search Algorithm for Video Tracking</a>. Doctoral thesis,
            <a href="https://www.ingenieria.uaslp.mx/" lang="es">Universidad AutÃ³noma de San Luis PotosÃ­</a>. Advisors:
            <a href="https://orcid.org/0000-0002-2435-3340" itemprop="colleague">Puente,Â C.</a> & <a
                href="https://orcid.org/0000-0002-0179-3933" itemprop="colleague">Soubervielleâ€‘Montalvo,Â C.</a>
            <details>
                <summary>More</summary>
                <p>This research project studies how to design and evaluate a real-time video tracking HSA-based
                    multiprocessing system that uses a SoC-FPGA platform. This task is performed with the intention of
                    answering if a given video tracker can be accelerated while maintaining its precision using that
                    system. However other important variables are observed such as power consumption and area. The
                    presented study follows a general research methodology which is divided in three main phases:
                    research definition, model design, and model evaluation.
            </details><img alt="ðŸ“˜" class="emoji"
                src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f4d8.svg"> <a
                href="https://orcid.org/0000-0002-0110-5475" itemprop="identifier">Perezâ€‘Cham,Â O.Â E.</a> (2017). <a
                href="https://www.researchgate.net/publication/352006074_Parallelization_of_the_Honeybee_Search_Algorithm_for_Video_Tracking">Parallelization
                of the Honeybee Search Algorithm for Video Tracking</a>. Master's thesis, <a
                href="https://www.ingenieria.uaslp.mx/" lang="es">Universidad AutÃ³noma de San Luis PotosÃ­</a>. Advisor:
            <a href="https://orcid.org/0000-0002-2435-3340" itemprop="colleague">Puente,Â C.</a>
            <details>
                <summary>More</summary>
                <p>Video tracking is one of the many problems in the field of Computer Vision; it is a basic component
                    for many and more complex vision systems that are useful for several real world applications in the
                    areas of medical research, surveillance, robotics, tele-collaboration, etc. A video tracking
                    algorithm tries to follow an object of interest trough the frames of a given video sequence. This
                    thesis studies the effects of performing video tracking aided by the Honeybee Search Algorithm, a
                    Swarm Intelligence (SI) algorithm that is inspired in the foraging behavior of honeybees; and
                    Graphics Processing Units (GPUs), which are an example of a Parallel Computing technology designed
                    specifically for graphic rendering operations. The results prove that it is possible to parallelize
                    the Honeybee Search Algorithm and use it for video tracking. In comparison with a parallel version
                    of the same video tracking algorithm, the addition of the Honeybee Search Algorithm helps to provide
                    a more stable time to deliver results, making them less dependent on the size of the specific video,
                    and without causing notable negative effects in the accuracy of the results.
            </details>
        </section>
        <section>
            <h2>OtherÂ papers</h2>
            <hr><img alt="ðŸ“„" class="emoji" src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f4c4.svg">
            <a href="https://www.researchgate.net/profile/Amado-Cardenas"
                itemprop="colleague">HernÃ¡ndezâ€‘CÃ¡rdenas,Â A.Â Y.</a>, <a href="https://orcid.org/0000-0002-0110-5475"
                itemprop="identifier">Perezâ€‘Cham,Â O.Â E.</a>, <a href="https://www.researchgate.net/profile/Rafael-Pena"
                itemprop="colleague">PeÃ±aâ€‘Gallardo,Â R.</a>, & <a href="https://orcid.org/0000-0002-0179-3933"
                itemprop="colleague">Soubervielleâ€‘Montalvo,Â C.</a> (2022). <a
                href="https://www.researchgate.net/publication/369920490_Implementacion_del_operador_de_Sobel_en_FPGA"
                lang="es">ImplementaciÃ³n del operador de Sobel en FPGA</a>. InÂ <a
                href="https://isbnmexico.indautor.cerlalc.org/catalogo.php?mode=detalle&nt=387957" lang="es">Avances en
                circuitos, sistemas y computaciÃ³n</a>. <a href="https://www.ingenieria.uaslp.mx/" lang="es">Universidad
                AutÃ³noma de San Luis PotosÃ­</a>.<details>
                <summary>More</summary>
                <p lang="es">operador Sobel; FPGA; detecciÃ³n de bordes
                <p lang="es">En este artÃ­culo se presenta la implementaciÃ³n en FPGA y el anÃ¡lisis del funcionamiento del
                    operador Sobel para la detecciÃ³n de bordes en imÃ¡genes. Originalmente este operador es una operaciÃ³n
                    matemÃ¡tica de convoluciÃ³n entre una seÃ±al y un filtro, que nos permite ver la variaciÃ³n de los
                    pixeles en una imagen. Se concluyÃ³ que se puede simplificar el algoritmo de dicho operador mediante
                    operaciones bÃ¡sicas como sumas y restas. Se obtuvo como resultado un sistema que logra procesar los
                    datos de una imagen por medio de la FPGA.
            </details><img alt="ðŸ“„" class="emoji"
                src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f4c4.svg"> <a
                href="https://www.researchgate.net/profile/Victor-Alejandro-Mendez-Lopez-2"
                itemprop="colleague">MÃ©ndezâ€‘LÃ³pez,Â V.Â A.</a>, <a href="https://orcid.org/0000-0002-0179-3933"
                itemprop="colleague">Soubervielleâ€‘Montalvo,Â C.</a>, <a href="https://orcid.org/0000-0002-2435-3340"
                itemprop="colleague">Puente,Â C.</a>, & <a href="https://orcid.org/0000-0002-0110-5475"
                itemprop="identifier">Perezâ€‘Cham,Â O.Â E.</a> (2022). <a
                href="https://www.researchgate.net/publication/369920755_Sistema_para_video_tracking_por_medio_de_SoC-FPGA_y_algoritmos_de_Inteligencia_de_Enjambre"
                lang="es">Sistema para video tracking por medio de SoC-FPGA y algoritmos de Inteligencia de
                Enjambre</a>. InÂ <a href="https://isbnmexico.indautor.cerlalc.org/catalogo.php?mode=detalle&nt=387957"
                lang="es">Avances en circuitos, sistemas y computaciÃ³n</a>. <a href="https://www.ingenieria.uaslp.mx/"
                lang="es">Universidad AutÃ³noma de San Luis PotosÃ­</a>.<details>
                <summary>More</summary>
                <p lang="es">SoC-FPGA; visiÃ³n artificial; inteligencia de enjambre
                <p lang="es">El seguimiento de objetos en video o video tracking es una tÃ©cnica de visiÃ³n computacional
                    que permite identificar de forma automÃ¡tica el movimiento en video de un objeto cualquiera. Una
                    manera de lograr esto es implementando algoritmos bioinspirados en sistemas de hardware de cÃ³mputo
                    heterogÃ©neo. Dicha tÃ©cnica es especialmente Ãºtil en el desarrollo de aplicaciones portÃ¡tiles de
                    procesamiento de video que, a fin de lograr una alta precisiÃ³n en dicha tarea, requieren de un alto
                    desempeÃ±o computacional en conjunto con un bajo consumo de energÃ­a. En este documento se describen
                    algunas consideraciones importantes para mejorar el rendimiento de un futuro sistema de seguimiento
                    de video implementado sobre estas tecnologÃ­as.
            </details><img alt="ðŸ“„" class="emoji"
                src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f4c4.svg"> <a
                href="https://www.linkedin.com/in/luisoortega-soportetecnico1/"
                itemprop="colleague">Ortegaâ€‘GutiÃ©rrez,Â L.Â O.</a>, <a href="https://orcid.org/0000-0002-0179-3933"
                itemprop="colleague">Soubervielleâ€‘Montalvo,Â C.</a>, <a href="https://orcid.org/0000-0002-2239-4755"
                itemprop="colleague">Arjonaâ€‘VillicaÃ±a,Â P.Â D.</a>, <a href="https://orcid.org/0000-0003-4813-8992"
                itemprop="colleague">NuÃ±ezâ€‘Varela,Â A.Â S.</a>, & <a href="https://orcid.org/0000-0002-0110-5475"
                itemprop="identifier">Perezâ€‘Cham,Â O.Â E.</a> (2022). <a
                href="https://www.researchgate.net/publication/369920667_Metodologia_basada_en_componentes_virtuales_para_el_desarrollo_de_redes_inalambricas_de_sensores"
                lang="es">MetodologÃ­a basada en componentes virtuales para el desarrollo de redes inalÃ¡mbricas de
                sensores</a>. InÂ <a href="https://isbnmexico.indautor.cerlalc.org/catalogo.php?mode=detalle&nt=387957"
                lang="es">Avances en circuitos, sistemas y computaciÃ³n</a>. <a href="https://www.ingenieria.uaslp.mx/"
                lang="es">Universidad AutÃ³noma de San Luis PotosÃ­</a>.<details>
                <summary>More</summary>
                <p lang="es">WSN, ZigBee, co-design, componentes virtuales, XML
                <p lang="es">Ante la reciente necesidad de automatizar el monitoreo de entornos tanto internos como
                    externos, surge la necesidad de encontrar tecnologÃ­as que lo permitan. Una de ellas es implementar
                    una red inalÃ¡mbrica de sensores (WSN, Wireless Sensor Networks) en la que se distribuyen sistemas
                    embebidos autÃ³nomos de bajo costo conocidos como Motes. Estos Motes contienen en su interior,
                    Software embebido personalizado y por lo general, se emplean dos o mÃ¡s microcontroladores en su
                    desarrollo, pero sin seguir una metodologÃ­a de desarrollo ademÃ¡s de ser difÃ­ciles de programar. Lo
                    anterior, incrementa el costo de las WSN, su consumo de energÃ­a y tiempos de desarrollo. En este
                    artÃ­culo se presenta una metodologÃ­a genÃ©rica basada en componentes virtuales de Hardware para
                    implementar una WSN de forma Ã¡gil y a bajo costo. Dicha metodologÃ­a facilita el trabajo no solo del
                    programador a nivel de Hardware sino del programador a nivel de aplicaciones.
            </details><img alt="ðŸ“„" class="emoji"
                src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f4c4.svg"> <a
                href="https://www.researchgate.net/profile/Cristopher-Zadquiel-Perez-Gonzalez"
                itemprop="colleague">PÃ©rezâ€‘GonzÃ¡lez,Â C.Â Z.</a>, <a href="https://orcid.org/0000-0002-0110-5475"
                itemprop="identifier">Perezâ€‘Cham,Â O.Â E.</a>, <a href="https://orcid.org/0000-0002-2435-3340"
                itemprop="colleague">Puente,Â C.</a>, & <a href="https://orcid.org/0000-0002-0179-3933"
                itemprop="colleague">Soubervielleâ€‘Montalvo,Â C.</a> (2022). <a
                href="https://www.researchgate.net/publication/369920670_Interfaz_portable_para_el_seguimiento_de_objetos_en_video_utilizando_el_algoritmo_de_abejas"
                lang="es">Interfaz portable para el seguimiento de objetos en video utilizando el algoritmo de
                abejas</a>. InÂ <a href="https://isbnmexico.indautor.cerlalc.org/catalogo.php?mode=detalle&nt=387957"
                lang="es">Avances en circuitos, sistemas y computaciÃ³n</a>. <a href="https://www.ingenieria.uaslp.mx/"
                lang="es">Universidad AutÃ³noma de San Luis PotosÃ­</a>.<details>
                <summary>More</summary>
                <p lang="es">HSA; portabilidad; seguimiento de objetos en video
                <p lang="es">Este articulo propone la implementaciÃ³n de una interfaz amigable y portable para un sistema
                    de seguimiento de objetos en video. Dicha interfaz permite demostrar la efectividad del algoritmo de
                    una manera visual y comprensible para investigadores de Ã¡reas ajenas a la visiÃ³n computacional e
                    inteligencia artificial. La soluciÃ³n busca resolver el problema de seguimiento de objetos en video,
                    que consiste en estimar en el tiempo y espacio la ubicaciÃ³n de un objeto mÃ³vil capturado por una
                    cÃ¡mara. Para lograr el objetivo se implementa el algoritmo de bÃºsqueda de abejas, una metaheurÃ­stica
                    inspirada en la manera en la que las abejas buscan comida en su entorno lo que permite un uso
                    eficiente de los recursos de cÃ³mputo.
            </details><img alt="ðŸ“„" class="emoji"
                src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f4c4.svg"> <a
                href="https://www.linkedin.com/in/luisoortega-soportetecnico1/"
                itemprop="colleague">Ortegaâ€‘GutiÃ©rrez,Â L.Â O.</a>, <a href="https://orcid.org/0000-0002-0179-3933"
                itemprop="colleague">Soubervielleâ€‘Montalvo,Â C.</a>, <a href="https://orcid.org/0000-0002-2239-4755"
                itemprop="colleague">Arjonaâ€‘VillicaÃ±a,Â P.Â D.</a>, & <a href="https://orcid.org/0000-0002-0110-5475"
                itemprop="identifier">Perezâ€‘Cham,Â O.Â E.</a> (2022). <a
                href="https://www.researchgate.net/publication/363680786_Plataforma_de_HWSW_basada_en_componentes_virtuales_para_el_desarrollo_agil_de_redes_de_sensores_inalambricas_de_bajo_costo"
                lang="es">Plataforma de HW/SW basada en componentes virtuales para el desarrollo Ã¡gil de redes de
                sensores inalÃ¡mbricas de bajo costo</a>. InÂ <a
                href="https://uaslpedu-my.sharepoint.com/personal/portal_iico_uaslp_mx/Documents/memoria%20final%202022.pdf"
                lang="es">Memorias del Premio de InstrumentaciÃ³n y ElectrÃ³nica 2022, â€œDr. Gustavo del Castillo y
                Gamaâ€</a>. <a href="https://www.ingenieria.uaslp.mx/" lang="es">Universidad AutÃ³noma de San Luis
                PotosÃ­</a>.<details>
                <summary>More</summary>
                <p lang="es">WSN; <span lang="en">ZigBee</span>; Mote; XML; GUI; componente virtual
                <p lang="es">Actualmente, la implementaciÃ³n de redes de sensores inalÃ¡mbricas (WSN, <span
                        lang="en">Wireless Sensor Networks</span>) se realiza por medio de software embebido
                    personalizado para los diferentes nodos que las conforman. ComÃºnmente se emplean dos o mÃ¡s
                    microcontroladores (MCU) para el desarrollo de cada nodo sensor o Mote. Un MCU se utiliza como radio
                    (dedicado al protocolo inalÃ¡mbrico), los demÃ¡s MCU se usan para la adquisiciÃ³n y acondicionamiento
                    de las seÃ±ales obtenidas por los sensores. Lo anterior, incrementa el costo de las WSN, su consumo
                    de energÃ­a y los tiempos de desarrollo, causando problemas de mantenimiento y escalabilidad. En este
                    artÃ­culo se presenta una plataforma de HW/SW basada en el <span lang="en">Core XBee PRO S2B</span>
                    para implementar de forma Ã¡gil una WSN para monitoreo ambiental de bajo costo con topologÃ­a de
                    estrella basada en el protocolo <span lang="en">ZigBee</span>. Dicha plataforma tiene la ventaja de
                    facilitar la configuraciÃ³n de sensores analÃ³gicos o digitales por medio de componentes virtuales,
                    ademÃ¡s de generar el software embebido para los diferentes Motes (<span lang="en">Router</span> o
                    <span lang="en">End-Devices</span>) de la WSN. Los componentes virtuales son interfaces grÃ¡ficas de
                    usuario (GUI, <span lang="en">Graphic User Interface</span>) que se desarrollan mediante el lenguaje
                    extendido de marcado (XML, <span lang="en">Extended Markup Language</span>) y consideran pines
                    especÃ­ficos para conectar diferentes sensores en nuestro prototipo de hardware que se indican
                    mediante un <span lang="en">pin-map</span>. La comparaciÃ³n en cuanto a costo, consumo energÃ©tico,
                    mantenibilidad y escalabilidad con respecto a otras plataformas del estado del arte, confirma que
                    nuestra propuesta es una mejor opciÃ³n para implementar este tipo de WSN.
            </details><img alt="ðŸ“„" class="emoji"
                src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f4c4.svg"><a
                href="https://orcid.org/0000-0002-0110-5475" itemprop="identifier"> Perezâ€‘Cham,Â O.Â E.</a>, <a
                href="https://orcid.org/0000-0002-0179-3933" itemprop="colleague">Soubervielleâ€‘Montalvo,Â C.</a>, & <a
                href="https://orcid.org/0000-0002-2435-3340" itemprop="colleague">Puente,Â C.</a> (2021). <a
                href="https://www.researchgate.net/publication/358156747_Sistema_Embebido_Evolutivo_para_el_Seguimiento_de_Objetos_en_Video"
                lang="es">Sistema Embebido Evolutivo para el Seguimiento de Objetos en Video</a>. InÂ <a
                href="https://uaslpedu-my.sharepoint.com/personal/portal_iico_uaslp_mx/Documents/Memorias%202021.pdf"
                lang="es">Memorias del Premio de InstrumentaciÃ³n y ElectrÃ³nica 2021, â€œDr. Gustavo del Castillo y
                Gamaâ€</a>. <a href="https://www.ingenieria.uaslp.mx/" lang="es">Universidad AutÃ³noma de San Luis
                PotosÃ­</a>.<details>
                <summary>More</summary>
                <p lang="es">SoC-FPGA; HSA; embebido; evolutivo
                <p lang="es">El presente trabajo describe el diseÃ±o, implementaciÃ³n y evaluaciÃ³n de un sistema embebido
                    evolutivo para realizar el seguimiento de objetos en video, basado en una plataforma SoC-FPGA y una
                    metaheurÃ­stica llamada HSA, que combina los enfoques de CÃ³mputo Evolutivo e Inteligencia de
                    Enjambre. Se emplea la medida de semejanza de ZNCC como funciÃ³n objetivo del HSA. Los resultados
                    muestran que la combinaciÃ³n de SoC-FPGA, HSA y ZNCC reducen el uso de recursos computacionales y
                    consumo de energÃ­a, permitiendo el multiprocesamiento en tiempo real sin reducciÃ³n de la exactitud.
                    El sistema embebido evolutivo que se propone para el seguimiento de objetos en video tiene
                    potenciales aplicaciones en diferentes Ã¡reas como son: la robÃ³tica, tecnologÃ­a para vehÃ­culos no
                    tripulados, tecnologÃ­a para drones, automatizaciÃ³n de procesos mediante visiÃ³n artificial, entre
                    otros.
            </details><img alt="ðŸ“„" class="emoji"
                src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f4c4.svg"> <a
                href="https://orcid.org/0000-0002-0110-5475" itemprop="identifier">Perezâ€‘Cham,Â O.Â E.</a>, <a
                href="https://orcid.org/0000-0002-0179-3933" itemprop="colleague">Soubervielleâ€‘Montalvo,Â C.</a>, & <a
                href="https://orcid.org/0000-0002-2435-3340" itemprop="colleague">Puente,Â C.</a> (2019). <a
                href="https://www.researchgate.net/publication/351952336_Propuesta_de_una_Solucion_Embebida_para_el_Seguimiento_de_Objetos_en_Video"
                lang="es">Propuesta de una SoluciÃ³n Embebida para el Seguimiento de Objetos en Video</a>. InÂ <a
                href="https://uaslpedu-my.sharepoint.com/personal/carao_cro_uaslp_mx/Documents/salinas/Documents/Memorias/Libro_AvancesCircuitosSistemas_2019.pdf"
                lang="es">Avances en Circuitos y Sistemas</a>. <a href="https://www.ingenieria.uaslp.mx/"
                lang="es">Universidad AutÃ³noma de San Luis PotosÃ­</a>.<details>
                <summary>More</summary>
                <p lang="es">seguimiento de objetos en video; inteligencia de enjambre; arreglo de compuertas
                    programables en campo
                <p lang="es">En este artÃ­culo se revisan varias arquitecturas computacionales para determinar cuÃ¡l es la
                    mÃ¡s apropiada para acelerar el Algoritmo de BÃºsqueda de las Abejas usado para el seguimiento de
                    objetos en video. Se llega a la conclusiÃ³n de que es necesario un sistema heterogÃ©neo que contenga
                    un CPU y una FPGA (Arreglo de Compuertas Programables en Campo). Como conclusiÃ³n se propone un
                    sistema heterogÃ©neo basado en una plataforma SoC-FPGA.
            </details><img alt="ðŸ“„" class="emoji"
                src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f4c4.svg"> <a
                href="https://www.linkedin.com/in/karina-castillo-7a167165/"
                itemprop="colleague">Castilloâ€‘FrÃ­as,Â A.Â K.</a>, <a href="https://orcid.org/0000-0002-0110-5475"
                itemprop="identifier">Perezâ€‘Cham,Â O.Â E.</a>, & <a
                href="https://www.linkedin.com/in/hugo-gallardo-garcia-b7643718/"
                itemprop="colleague">Gallardoâ€‘Garcia,Â H.</a> (2012). <a
                href="https://sciencesummit.tec.mx/sites/g/files/vgjovo771/files/42_Compendio_de_Investigacion.pdf"
                lang="es">ImplementaciÃ³n del uso de energÃ­a solar automatizada por dispositivos electrÃ³nicos aplicada al
                proceso de producciÃ³n sustentable del mezcal</a>. In <a
                href="https://sciencesummit.tec.mx/compendios-anteriores" lang="es">42Â°Â Congreso de InvestigaciÃ³n y
                Desarrollo</a>. <a href="https://tec.mx/" lang="es">Instituto TecnolÃ³gico y de Estudios Superiores de
                Monterrey</a>.<details>
                <summary>More</summary>
                <p lang="es">Esta investigaciÃ³n es parte del proyecto â€œImplementaciÃ³n del uso de energÃ­a solar
                    automatizada por dispositivos electrÃ³nicos aplicada al proceso de producciÃ³n sustentable del
                    mezcalâ€, patrocinado por CONACyT. El proyecto se basa en el desarrollo de una herramienta que
                    permita predecir la configuraciÃ³n ideal de parÃ¡metros de un colector solar mediante el diseÃ±o y
                    anÃ¡lisis de experimentos utilizando los datos de la herramienta. AdemÃ¡s el proyecto resultarÃ¡ Ãºtil
                    para estimar la eficiencia del trabajo de un colector solar ya construido al reproducir los
                    parÃ¡metros del colector en la interfaz. Se diseÃ±Ã³ una interfaz en LabVIEW que muestra grÃ¡ficamente y
                    en tiempo real la mediciÃ³n de un piranÃ³metro, instrumento con la funciÃ³n de medir la radiaciÃ³n
                    solar. El proyecto se enfoca a concentradores solares del tipo cilÃ­ndrico parabÃ³lico. En la interfaz
                    se tienen varias opciones de materiales con los que el usuario, en una interfaz amigable, puede
                    seleccionar diferentes opciones, comparar los modelos propuestos y obtener el mejor resultado para
                    satisfacer sus necesidades. Con esta interfaz se puede simular el funcionamiento de los
                    concentradores, asÃ­ como realizar pronÃ³sticos para cierto tipo de variables como temperatura de
                    salida. Gracias a que se tienen los datos en tiempo real, la simulaciÃ³n es adaptable a cualquier
                    medio y se puede probar en distintos lugares. Esta aplicaciÃ³n entrega un reporte cada cierto
                    intervalo de tiempo con los datos del modelo, para despuÃ©s utilizarlos para los fines que se deseen
                    como realizar anÃ¡lisis de datos, grÃ¡ficas, tablas etcÃ©tera.
            </details>
        </section>
        <section>
            <h2>Technical reports</h2><img alt="ðŸ“„" class="emoji"
                src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f4c4.svg"> <a
                href="https://orcid.org/0000-0002-0110-5475" itemprop="identifier">Perezâ€‘Cham,Â O.Â E.</a>, <a
                href="https://orcid.org/0000-0002-0179-3933" itemprop="colleague">Soubervielleâ€‘Montalvo,Â C.</a>, <a
                href="https://orcid.org/0000-0002-2435-3340" itemprop="colleague">Puente,Â C.</a>, <a
                href="https://www.researchgate.net/profile/G-Flores-Erana" itemprop="colleague">Floresâ€‘EraÃ±aÂ G.</a>, <a
                href="https://orcid.org/0000-0003-2117-4803" itemprop="colleague">Limonâ€‘Romero,Â J.</a>, & <a
                href="https://www.researchgate.net/profile/Jose-Altamirano-Flores"
                itemprop="colleague">Altamiranoâ€‘Flores,Â J.Â S.</a> (2022). <a
                href="https://www.researchgate.net/publication/359746644_Dataset_to_Evaluate_Heterogeneous_Computing_Systems_that_Implement_the_Honeybee_Search_Algorithm_for_Object_Tracking">Dataset
                to Evaluate Heterogeneous Computing Systems that Implement the Honeybee Search Algorithm for Object
                Tracking</a>. <a
                href="http://doi.org/10.13140/rg.2.2.35500.95360">http://doi.org/10.13140/rg.2.2.35500.95360</a>
            <details>
                <summary>More</summary>
                <p>There is an increasing demand for computer vision systems that provide high precision, realâ€‘time
                    processing, portability, and lowâ€‘power consumption for applications in fields such as robotics,
                    automation, and surveillance, among other areas of study. One important task in these areas is
                    object tracking. In this article, we describe the methods and the dataset used to evaluate
                    heterogeneous computing systems that implement the Honeybee Search Algorithm (HSA) to perform object
                    tracking. HSA is a metaâ€‘heuristic that combines techniques from evolutionary computing and swarm
                    intelligence. The data analysis revealed that the combination of SoCâ€‘FPGA and HSA enables realâ€‘time
                    multiprocessing, lower power consumption, and portability without sacrificing precision. It also
                    shows that SoCâ€‘FPGA devices outperform CPUâ€‘GPU devices in metaâ€‘heuristic focused implementations for
                    computer vision applications. We hope that providing access to the dataset might increase research
                    on the combination of SoCâ€‘FPGA platforms and metaâ€‘heuristics which has not been explored
                    sufficiently. The dataset availability can serve to replicate our experiments and to contrast new
                    proposed approaches with our results.
            </details>
        </section>
        <section>
            <h2>Posters</h2>
            <hr><img alt="ðŸ–¼ï¸" class="emoji" src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f5bc.svg">
            <a href="https://orcid.org/0000-0002-0110-5475" itemprop="identifier">Perezâ€‘Cham,Â O.Â E.</a>, <a
                href="https://orcid.org/0000-0002-0179-3933" itemprop="colleague">Soubervielleâ€‘Montalvo,Â C.</a>, & <a
                href="https://orcid.org/0000-0002-2435-3340" itemprop="colleague">Puente,Â C.</a> (2019). <a
                href="https://www.researchgate.net/publication/355092843_Propuesta_de_una_Solucion_Embebida_para_el_Seguimiento_de_Objetos_en_Video"
                lang="es">Propuesta de una SoluciÃ³n Embebida para el Seguimiento de Objetos en Video</a>. Event: <a
                href="https://agenciadenoticiasslp.com/2019/03/08/concys-2019-de-la-uaslp-proyecta-amplias-actividades-de-divulgacion/"
                lang="es">2do Congreso Nacional de Circuitos y Sistemas (CONCYS 2019)</a>.<br><img alt="ðŸ–¼ï¸"
                class="emoji" src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f5bc.svg"> <a
                href="https://orcid.org/0000-0002-0110-5475" itemprop="identifier">Perezâ€‘Cham,Â O.Â E.</a>, & <a
                href="https://orcid.org/0000-0002-2435-3340" itemprop="colleague">Puente,Â C.</a> (2018). <a
                href="https://www.researchgate.net/publication/355094019_Paralelizacion_del_Algoritmo_de_Busqueda_de_las_Abejas_para_el_seguimiento_de_objetos_en_video"
                lang="es">ParalelizaciÃ³n del Algoritmo de BÃºsqueda de las Abejas para el seguimiento de objetos en
                video</a>. Event: <a
                href="https://www.elsoldesanluis.com.mx/local/ingenieria-realiza-la-4a.-edicion-puertas-abiertas-1646803.html"
                lang="es">Puertas Abiertas 2018 â€œPosgrados de IngenierÃ­a a tu alcanceâ€</a>.<br><img alt="ðŸ–¼ï¸"
                class="emoji" src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/1f5bc.svg"> <a
                href="https://orcid.org/0000-0002-0110-5475" itemprop="identifier">Perezâ€‘Cham,Â O.Â E.</a>, & <a
                href="https://orcid.org/0000-0002-2435-3340" itemprop="colleague">Puente,Â C.</a> (2016). <a
                href="https://www.researchgate.net/publication/355092182_Computo_Evolutivo" lang="es">CÃ³mputo
                Evolutivo</a>. Event: <span lang="es">Puertas Abiertas 2016 â€œPosgrados de IngenierÃ­a a tu
                alcanceâ€</span>.
        </section>
        <section>
            <h2>PeerÂ review</h2>
            <hr><img alt="âœ’" class="emoji" src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/2712.svg">
            Reviewer for <a href="https://www.springer.com/journal/11227/">The Journal of Supercomputing</a> (2023).
            Once: <a href="https://publons.com/wos-op/review/author/2C7yadLD/"><code>2C7yadLD</code></a>.<br><img
                alt="âœ’" class="emoji" src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/2712.svg"> Reviewer
            for <a href="https://ieeeaccess.ieee.org/">IEEE Access</a> (2023). Two times: <a
                href="https://publons.com/wos-op/review/author/Fs9XTNlr/"><code>Fs9XTNlr</code></a>, <a
                href="https://publons.com/wos-op/review/author/aPWsiiLc/"><code>aPWsiiLc</code></a>.<br><img alt="âœ’"
                class="emoji" src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/2712.svg"> Reviewer for <a
                href="https://www.mdpi.com/journal/electronics">Electronics</a> (2022). Once: <a
                href="https://publons.com/wos-op/review/author/raLemJUa/"><code>raLemJUa</code></a>.<br><img alt="âœ’"
                class="emoji" src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/2712.svg"> Reviewer for <a
                href="https://ieeeaccess.ieee.org/">IEEE Access</a> (2022). Four times: <a
                href="https://publons.com/wos-op/review/author/K9KFzCPe/"><code>K9KFzCPe</code></a>, <a
                href="https://publons.com/wos-op/review/author/b1UBHTkJ/"><code>b1UBHTkJ</code></a>, <a
                href="https://publons.com/wos-op/review/author/v3ryBNEy/"><code>v3ryBNEy</code></a>, <a
                href="https://publons.com/wos-op/review/author/2AyJ7zD3/"><code>2AyJ7zD3</code></a>.<br><img alt="âœ’"
                class="emoji" src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/2712.svg"> Reviewer for <a
                href="https://cis.ieee.org/publications/t-evolutionary-computation">IEEE Transactions on Evolutionary
                Computation</a> (2022). Once: <a
                href="https://publons.com/wos-op/review/author/NutEyQg2/"><code>NutEyQg2</code></a>.<br><img alt="âœ’"
                class="emoji" src="https://cdnjs.cloudflare.com/ajax/libs/twemoji/14.0.2/svg/2712.svg"> Reviewer for <a
                href="https://ieeeaccess.ieee.org/">IEEE Access</a> (2020). Two times: <a
                href="https://publons.com/wos-op/review/author/CEKhlkaf/"><code>CEKhlkaf</code></a>, <a
                href="https://publons.com/wos-op/review/author/E1Ewa9TT/"><code>E1Ewa9TT</code></a>.
        </section>
